本文中我们考虑如下有约束的一般优化问题的求解方法：
$$\begin{aligned} &\min f(x) \\ \text{s. t. } &c_{i}(x) = 0, i\in E=\{1,2,\dots, l\}\\  & c_{i}(x)\leq 0, i\in I = \{l+1, l+2,\dots,l+m\} \\  & x\in \mathbb{R}^{n} \end{aligned}$$ 其中，可行域 $D$ 记为：
$$D=\{x | c_{i}(x)=0, i\in E; c_{i}(x)\leq 0, i\in I; x\in\mathbb{R}^{n}\}$$

求解约束优化问题要比求解[无约束优化问题](http://blog.csdn.net/philthinker/article/details/78191864)复杂困难得多。一般来说，求解约束优化问题的方法大致分两类：一类是[此文](http://blog.csdn.net/philthinker/article/details/78510361)中介绍的直接求解法，另一类是本文中即将介绍的罚函数法。

罚函数法是利用目标函数 $f(x)$ 和约束函数 $c(x)$，构造具有惩罚性质的函数 $P(x)=\bar{P}(f(x), c(x))$ ，使得原约束优化问题转化为求 $P(x)$ 最优解的无约束优化问题。以下讨论中，我们假设**所有函数都是连续的**。

@[toc]

# 外罚函数法
外罚函数是一类不可行点的方法，其基本思想是：在求解约束优化的问题时，通过对不可行的迭代点施加惩罚，并随着迭代点的进展，增大惩罚量，迫使迭代点逐步向可行域靠近。

## 等式约束的优化问题
$$\begin{aligned} &\min f(x), x\in\mathbb{R}^{n} \\ \text{s. t. }& c_{i}(x)=0, i=1,2,\dots,l  \end{aligned}$$记$$\tilde{P}(x)=\sum_{i=1}^{l}|c_{i}(x)|^{\beta},\quad \beta\geq 1$$定义如下形式的外罚函数$$\begin{aligned} P(x,\sigma) &= f(x)+\sigma \tilde{P}(x) \\ &= f(x)+\sigma\sum_{i=1}^{l}|c_{i}(x)|^{\beta},\quad \beta\geq 1 \end{aligned}$$其中 $\sigma>0$ 是一个参数。显然，当 $x$ 为可行点时，$\tilde{P}(x)=0$ ；当 $x$ 不是可行点时 $\tilde{P}(x)>0$ ，于是 $P(x,\sigma)>f(x)$ 。特别的，随着 $\sigma$ 增大，$P(x)$ 也在增大。所以，要使 $P(x,\sigma)$ 取到极小值， $\tilde{P}(x)$ 应充分小，即 $P(x,\sigma)$ 的极小点应充分逼近可行域。于是，上述等式约束优化问题转化为无约束优化的问题
$$\min_{x}\{P(x,\sigma)=f(x)+\sigma\tilde{P}(x) \}$$通常取$\beta=2$ 。

**例 1**：求解下列约束优化问题$$\begin{aligned}\min\{f(x)=x_{1}+x_{2}\}\\\text{s. t. } c(x)=x_{2}-x_{1}^{2} =0 \end{aligned}$$解：构造外罚函数$$P(x,\sigma)=x_{1}+x_{2}+\sigma(x_{2}-x_{1}^{2})^{2} $$利用解析法求解$$\frac{\partial P}{\partial x_{1}}=1-4\sigma x_{1}(x_{2}-x_{1}^{2}), \frac{\partial P}{\partial x_{2}}=1+2\sigma(x_{2}-x_{1}^{2})$$令$$\nabla_{x}P(x,\sigma)=0$$得到$$x_{1}(\sigma)=-\frac{1}{2}, x_{2}(\sigma)=\frac{1}{4}-\frac{1}{2\sigma}$$再令$\sigma\to+\infty$得$$\begin{aligned}x(\sigma)=\left(-\frac{1}{2}, \frac{1}{4} \right)^{T}=x^{*} \\ P(x(\sigma), \sigma)=-\frac{1}{4}=f(x^{*})\end{aligned}$$

## 不等式约束的优化问题
我们考虑如下不等式约束的优化问题
$$\begin{aligned} &\min f(x), x\in\mathbb{R}^{n} \\ \text{s. t. }& c_{i}(x)\leq 0, i=1,2,\dots,l  \end{aligned}$$记$$\tilde{P}(x)=\sum_{i=1}^{l}[\max(0, c_{i}(x))]^{\alpha},\quad \alpha\geq 1$$定义如下形式的外罚函数
$$P(x,\sigma)=f(x)+\sigma\sum_{i=1}^{l}[\max(0, c_{i}(x))]^{\alpha}\quad \alpha\geq 1$$此时的外罚函数性质与上一节类似，通常取 $\alpha=2$ 。

## 一般约束的优化问题
考虑一般的约束优化问题
$$\begin{aligned} &\min f(x) \\ \text{s. t. } &c_{i}(x) = 0, i\in E=\{1,2,\dots, l\}\\ &  c_{i}(x)\leq 0, i\in I = \{L+1, l+2,\dots,l+m\} \\ & x\in \mathbb{R}^{n} \end{aligned}$$ 记 $$\tilde{P}(x)=\sum_{i=1}^{l}|c_{i}(x)|^{\beta}+\sum_{i=1}^{l}[\max(0, c_{i}(x))]^{\alpha},\quad \alpha\geq 1,\beta\geq 1$$类似地，定义如下形式的外罚函数$$P(x,\sigma)=f(x)+\sigma\sum_{i=1}^{l}|c_{i}(x)|^{\beta}+\sum_{i=1}^{l}[\max(0, c_{i}(x))]^{\alpha},\quad \alpha\geq 1,\beta\geq 1$$上述罚函数性质与之前的讨论类似。通常 $\alpha=\beta =2$。可见，外罚函数的最优解在 $\sigma\to+\infty$的过程中一直在可行域外部取点，直到趋近最优解 $x^{*}$。所以之中方法为外罚函数法，简称**外点法**；$P(x,\sigma)$ 为外罚函数，或叫增广目标函数，$\sigma$为惩罚因子，$\tilde{P}(x)$为惩罚项。

对于比较复杂的约束，通常采用迭代的方法：

 1. 给定初始点 $x^{0}$，设$\epsilon >0, c>1$ 为给定实数，选择序列 $\{\sigma_{k}\}$，使得$\sigma_{k}\to+\infty$，令 $k=1$；
 2. 以 $x^{k-1}$ 为初始点，求解无约束优化问题$$\min\{P(x,\sigma_{k})=f(x)+\sigma_{k}\tilde{P}(x) \}$$得到最优解$x^{k}$。
 3. 若$\sigma_{k}\tilde{P}(x^{k})<\epsilon$，则停止迭代，$x^{k}$ 作为原问题的最优解；否则，令$\sigma_{k+1}=c\sigma_{k}$，$k:=k+1$，转至步骤2。

对于外罚函数的算法**收敛性**与外罚函数的**病态性质**这里不作讨论。 使用外罚函数法时，选取 $\sigma_{1}$过大，或者 $\sigma_{k}$增长过快可以使算法快速收敛，但很难精确地求解相应的无约束极小问题；反之，可以使求得$P(x,\sigma_{k+1})$的极小点变得容易，但收敛太慢。通常取 $\sigma_{k}=0.1\times 2^{k-1}$。

# 内罚函数法
在外罚函数法中，近似最优解一般只能近似地满足约束条件，对于某些实际问题这样的近似最优解释不可接受的。内罚函数法是一类保持严格可行性的方法。其基本思想是：严格要求迭代点在可行域内移动，当迭代点接近可行域边界时，有无穷大的障碍，迫使迭代点返回可行域的内部。

考虑不等式约束的优化问题，可行域内部记为：$$D^{0}=\{x\in\mathbb{R}^{n} | c_{i}(x)<0, i=1,2,\dots,l\}$$记$$B(x)=-\sum_{i=1}^{l}\ln(-c_{i}(x))$$ 定义如下形式的内罚函数：
$$\begin{aligned}P(x,r) &=f(x)+rB(x)\\ &=f(x)-r\sum_{i=1}^{l}\ln(-c_{i}(x))\end{aligned}$$其中 $r>0$ 是一参数。

显然，当 $x$ 在可行域内部，$B(x)$为一正数，当 $r$ 趋近于 $0$ 时， $P(x,r)$ 的极小点就会趋近于优化问题的极小点。至少有一个 $c_{i}(x)$ 趋于 $0$ 时，会导致 $B(x)$ 剧烈增大，迫使极小点落在可行域的内部。于是，原优化问题就转化为一下形式的优化问题：
$$\begin{aligned} &\min P(x,r), x\in\mathbb{R}^{n}\\ \text{s. t. }& c_{i}(x)<0, i=1,2,\dots, l \end{aligned}$$ 注意使用内罚函数时，可行域由 $D$ 变成 $D^{0}$ 。内罚函数法简称内点法，$B(x)$ 为对数障碍函数。（这里不介绍倒数障碍函数，因其用得不多性质也不佳）

**例 2**：用内罚函数法求解约束问题$$\begin{aligned} &\min\{f(x)=x_{1}^{2}+2x_{2}^{2}\} \\  \text{s. t. }& x_{1}+x_{2}-1\geq 0 \end{aligned}$$ 解：构造内罚函数
$$P(x(r),r)=x_{1}^{2}+2x_{2}^{2}-r\ln(x_{1}+x_{2}-1)$$利用解析法：
$$\nabla_{x}P(x(r),r)=\left( 2x_{1}-\frac{r}{x_{1}+x_{2}-1}, 4x_{2}-\frac{r}{x_{1}+x_{2}-1} \right)^{T}=0$$得
$$x(r)=\left( \frac{1+\sqrt{1+3r}}{3}, \frac{1+\sqrt{1+3r}}{6} \right)^{T}$$令 $r\to 0$ ，则
$$x(r)\to x^{*}=\left(\frac{2}{3}, \frac{1}{3}\right)^{T}, P(x(r),r)\to f(x^{*})=\frac{2}{3}$$

下面给出内罚函数法的算法，此处同样不讨论其收敛性和病态性质。

 1. 给定初始点 $x^{0}\in D^{0}$ ，设 $\epsilon>0, 0<c<1$为给定实数，选择正值序列 $\{r_{k}\}$ 使 $r_{k}\to0$，令 $k=1$。
 2. 以 $x^{k-1}$ 为初始点，求解约束优化问题$$\begin{aligned} &\min \{P(x,r_{k})=f(x)+r_{k}B(x)\} \\ \text{s. t. }& x\in D^{0} \end{aligned}$$得到最优解 $x^{k}$。
 3. 若 $r_{k}B(x^{k})<\epsilon$ ， 则停止迭代，$x^{k}$ 作为原问题的最优解；否则，令 $r_{k+1}=cr_{k}$ , $k:=k+1$，转至步骤2。

注意由于可行域发生了变化，$D^{0}$不能为空，因此**内罚函数法不能处理等式约束问题**。

# 乘子法
内外罚函数法的主要缺点是当罚函数中的 $\sigma\to+\infty$ 或者 $r\to0$ 时，其Hesse矩阵出现病态，给无约束问题的数值求解带来很大困难。为克服这一缺点，本节介绍乘子法。乘子法的原理与[二阶充分条件与Lagrange函数](http://blog.csdn.net/philthinker/article/details/78510361)的性质有关，时间问题这里不做详细推导，仅给出定理。

## 等式约束问题的乘子法
**定理**：
设 $x^{*}$, $\lambda^{*}$ 满足约束问题
$$\begin{aligned} &\min f(x), x\in\mathbb{R}^{n} \\ \text{s. t. }& c_{i}(x)=0, i=1,2,\dots,l  \end{aligned}$$的二阶充分条件，则存在 $\sigma^{*}>0$，使当 $\sigma\geq \sigma^{*}$ 时， $x^{*}$ 是无约束问题
$$\min\{\phi(x,\lambda^{*},\sigma) = f(x)+\sum_{i=1}^{l}\lambda_{i}^{*}c_{i}(x)+\frac{\sigma}{2}\sum_{i=1}^{l}c_{i}^{2}(x) \}$$的严格局部解。反之，若 $x^{k}$ 是 $\phi(x,\lambda^{*},\sigma_{k})$ 的极小点，并且 $c(x^{k})=0$，则 $x^{k}$ 是上述约束问题的最优解。

$\phi(\cdot)$ 被称为**增广Lagrange函数**或**乘子罚函数**，$\lambda^{*}$ 实际上是最优解 $x^{*}$ 处的Lagrange乘子。我们可以通过取一个适当大的 $\sigma$ ，然后调整 $\lambda$ 使它逐渐趋近于 $\lambda^{*}$ ，就能得到约束问题的最优解，这是乘子法的基本思想。

下面给出具体迭代算法：

 1. 给定初始点 $x^{0}$ ，设初始乘子 $\lambda^{1}$ ，精度要求为 $\epsilon$ ，放大系数为 $c$，选择序列 $\{\sigma_{k}\}$，使 $\sigma_{k}\to+\infty$，令 $k=1$。
 2. 以 $x^{k-1}$ 为初始点，求解无约束优化问题 $$\min_{x}\phi(x,\lambda^{k},\sigma_{k})$$得到最优解 $x^{k}$。
 3. 若 $[\sum_{i=1}^{l}c_{i}^{2}(x_{k})]^{\frac{1}{2}}\leq \epsilon$，则停止迭代，得到近似解 $x^{k}$；否则，转到步骤4。
 4. 令 $\lambda_{i}^{k+1}=\lambda_{i}^{k}+\sigma_{k}c_{i}(x^{k})$，$k:=k+1$，转到步骤2。

## 只有不等式约束时的乘子法
现在我们考虑只有不等式约束的问题：
$$\begin{aligned} &\min f(x), x\in\mathbb{R}^{n} \\ \text{s. t. }& c_{i}(x)\leq 0, i=1,2,\dots,l  \end{aligned}$$利用等式约束的结果，引入**松弛变量** $z_{i}$，将上述问题转化为等式约束问题
$$\begin{aligned} &\min f(x), x\in\mathbb{R}^{n} \\ \text{s. t. }& c_{i}(x)+z_{i}^{2}= 0, i=1,2,\dots,l  \end{aligned}$$由于变量增加了，因此问题的维度由 $n+l$ 变成 $\bar{n}+2l$ 。这使得问题变得复杂。为了克服此问题，我们可以先关于 $z$ 求极小 $\bar{z}$，再将其代入原问题。此处同样不讨论具体细节。

下面给出具体算法：

 1. 给定初始点 $x^{0}$ ，设初始乘子 $\lambda^{1}$ ，精度要求 $\epsilon$ ，放大系数为 $c$ ，选择序列 $\{\sigma_{k}\}$，使 $\sigma_{k}\to+\infty$，令 $k=1$。
 2. 以 $x^{k-1}$ 为初始点，求解无约束规划问题：$$\min_{x}\phi(x,\lambda^{k},\sigma_{k})$$得到最优解 $x^{k}$。
 3. 若 $\left\{\sum_{i=1}^{l}\left[\max\left(c_{i}(x^{k}), -\frac{\lambda_{i}^{k}}{\sigma_{k}}\right)\right]^{2}\right\}^{\frac{1}{2}}\leq \epsilon$，则停止迭代，得近似解 $x^{k}$ ；否则，转至步骤4。
 4. 令 $\lambda_{i}^{k+1}=\max\{0, \lambda_{i}^{k}+\sigma_{k}c_{i}(x^{k})\}, k:=k+1$，转至步骤2。

## 一般问题的乘子法求解
对于一般约束优化问题：
$$\begin{aligned} &\min f(x) \\ \text{s. t. } &c_{i}(x) = 0, i\in E=\{1,2,\dots, l\}\\  & c_{i}(x)\leq 0, i\in I = \{l+1, l+2,\dots,l+m\} \\  & x\in \mathbb{R}^{n} \end{aligned}$$ 乘子罚函数为
$$\phi(x,\lambda,\sigma)=f(x)+\sum_{i=1}^{l}\lambda_{i}c_{i}(x)+\frac{\sigma}{2}\sum_{i=1}^{l}c_{i}^{2}(x)+\frac{1}{2\sigma}\sum_{i=l+1}^{l+m}\{[\max(0, \lambda_{i}+\sigma c_{i}(x))]^{2}-\lambda_{i}^{2}\}$$其乘子迭代公式为：
$$\begin{aligned}&\lambda_{i}^{k+1}=\lambda_{i}^{k}+\sigma_{k}c_{i}(x^{k}),\quad &i=1,2,\dots,l\\&\lambda_{i}^{k+1}=\max\{0,\lambda_{i}^{k}+\sigma_{k}c_{i}(x^{k})\},\quad &i=l+1,l+2,\dots,l+m \end{aligned}$$终止准则为：
$$\left\{\sum_{i=1}^{l}c_{i}^{2}(x^{k})+\sum_{i=l+1}^{l+m}\left[\max\left(c_{i}(x^{k}), -\frac{\lambda_{i}^{k}}{\sigma_{k}}\right)\right]^{2}\right\}^{\frac{1}{2}}\leq\epsilon$$

关于Lagrange乘子法更一般的介绍可参考[此文](http://blog.csdn.net/philthinker/article/details/66473983)。
