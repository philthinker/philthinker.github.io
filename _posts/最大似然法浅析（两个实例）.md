# 最大似然法浅析（两个实例）

标签（空格分隔）： MachineLearning 

---

这里给出两个实例。

1.**伯努利分布**实例

假设 $P(X=1)=p,P(X=0)=1-p$ 综合起来就有
$$P(X)=p^{X}(1-p)^{1-X}$$
此时如果有一组数据 $D$ 是从这个随机变量中采样得到的，那么就有
$$
\begin{split}
\ max_{p}\log P(D)&= \max_{p}\log\prod_{i}^{N}P(D_{i}) \\
        &=\max_{p}\sum_{i}^{N}\log P(D_{i}) \\
        &=\max_{p}\sum_{i}^{N}[D_{i}\log p+(1-D_{i})\log(1-p)]
\end{split}
$$
对上式求导，则有
$$
\nabla_{p}\max_{p}\log P(D)=\sum_{i}^{N}[D_{i}\frac{1}{p}+(1-D_{i})\frac{1}{p-1}]
$$
求极值，令导数为 $0$，就有
$$
\begin{split}
& \sum_{i}^{N}[D_{i}\frac{1}{p}+(1-D_{i})\frac{1}{p-1}]=0 \\
& \sum_{i}^{N}[D_{i}(p-1)+(1-D_{i})p]=0 \\
& \sum_{i}^{N}(p-D_{i})=0 \\
& p=\frac{1}{N}\sum_{i}^{N}D_{i}
\end{split}
$$
即全部采样的平均值。

2.**高斯分布**实例

令 $p(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}$，采用同样的方法有
$$
\begin{split}
 \max_{p}\log P(D) &= \max_{p}\log\prod_{i}^{N}P(D_{i})  \\
		 &= \max_{p}\sum_{i}^{N}\log P(D_{i}) \\
		 &= \max_{p}\sum_{i}^{N}[-\frac{1}{2}\log(2\pi\sigma^{2})-\frac{(D_{i}-\mu)^{2}}{2\sigma^{2}}] \\\
		 &= \max[-\frac{N}{2}\log(2\pi\sigma^{2})-\frac{1}{2\sigma^{2}}\sum_{i}^{N}(D_{i}-\mu)^{2}]
 \end{split}
$$
此处包含两个参数，分别估计。

首先对 $\mu$ 求导，有
$$
\frac{\partial\max_{\mu}\log P(D)}{\partial \mu} = -\frac{1}{\sigma^{2}}\sum_{i}^{N}(\mu-D_{i})
$$
令导数为 $0$，有
$$
-\frac{1}{\sigma^{2}}\sum_{i}^{N}(\mu-D_{i})=0,\quad \mu=\frac{1}{N}\sum_{i}^{N}D_{i}
$$
其次对 $\sigma^{2}$ 求导，有
$$
\frac{\partial\max_{\sigma^{2}}\log P(D)}{\partial\sigma^{2}} = -\frac{N}{2\sigma^{2}}+\frac{1}{2\sigma^{4}}\sum_{i}^{N}(D_{i}-\mu)^{2}
$$
令导数为 $0$，有
$$
-\frac{N}{2\sigma^{2}}+\frac{1}{4\sigma^{4}}\sum_{i}^{N}(D_{i}-\mu)^{2}=0
$$
$$
\sigma^{2} = \frac{1}{N}\sum_{i}^{N}(D_{i}-\mu)^{2}
$$
可见最终计算结果与期望方差计算方式完全一致。


