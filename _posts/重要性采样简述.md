# 重要性采样简述

标签（空格分隔）： MachineLearning

---

重要性采样（Importance Sampling）是统计学中的一种采样方法。它主要用于一些难以直接采样的数据分布上。假设有一个很复杂的概率密度函数 $p(x)$ ，求解随机变量基于此概率下的某个函数期望，即
$$ E_{x\sim p(x)}[f(x)] $$
如果采用解析法：
$$ E_{x\sim p(x)}[f(x)] = \int_{x}p(x)f(x)\mathrm{d}x $$
如果 $f(x)$ 的形式非常复杂，直接求解变得非常困难。另一种解法是采用蒙特卡洛法。当采样的数量足够大时，采样的样本就可以无限接近原分布，基于此思想，求解公式变为：
$$ E_{x\sim p(x)}[f(x)] = \frac{1}{N}\sum_{x_{i}\sim p(x),i=1}^{N}f(x_{i}) $$
采样数量越多，近似效果越好，这也符合大数定理的解释。

当我们采样的时候遇到一些非常奇怪的概率分布，采样可能会遇到困难。比如说由深度神经网络构成的概率密度函数，我们只能通过输入给定的样本得到它的概率。这时重要性采样就派上用场了。令待采样的分布为 $p(x)$ ，另一个简单的定义域与 $p(x)$ 相同的分布为 $\tilde{p}(x)$，我们可以得到
$$
\begin{split} 
E_{x\sim p(x)}[f(x)] & = \int_{x}p(x)f(x)\mathrm{d}x \\
		& = \int_{x}\tilde{p}(x)\frac{p(x)}{\tilde{p}(x)}f(x)\mathrm{d}x \\
		& = E_{x\sim \tilde{p}(x)}[\frac{p(x)}{\tilde{p}(x)}f(x)] \\
		& \simeq \frac{1}{N}\sum_{x_{i}\sim\tilde{p}(x),i=1}^{N}\frac{p(x)}{\tilde{p}(x)}f(x)
\end{split}
$$
此时我们发现我们只需要从这个简单的分布 $\tilde{p}(x)$ 中进行采样，然后分布计算样本在两个分布中的 概率和函数值即可。

当然我们也不能太乐观，选择一个合适的采样分布对重要性采样尤为重要。要选择与原始分布尽可能接近的近似分布进行采样。



